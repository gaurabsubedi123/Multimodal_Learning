{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AxelAllen/Pre-trained-Multimodal-Text-Image-Classifier-in-a-Sparse-Data-Application/blob/master/run_mmbt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOnHITFCd61k"
      },
      "source": [
        "# Run MMBT Experiments\n",
        "\n",
        "This notebook shows the end-to-end pipeline for fine-tuning pre-trained MMBT model for multimodal (text and image) classification on our dataset.\n",
        "\n",
        "Parts of this pipeline are adapted from the\n",
        "Huggingface `run_mmimdb.py` script to execute the MMBT model. This code can\n",
        "be accessed [here.](https://github.com/huggingface/transformers/blob/8ea412a86faa8e9edeeb6b5c46b08def06aa03ea/examples/research_projects/mm-imdb/run_mmimdb.py#L305)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfB8X3Ldn7Ci",
        "outputId": "ebc1e99e-7646-4013-b3ca-8a1c1e81f363"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: NVIDIA GeForce RTX 2070 with Max-Q Design\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcFSbljwoMmO"
      },
      "source": [
        "## Install Huggingface Library\n",
        "\n",
        "These should have been installed during your environment set-up; you only need to run these cells in Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxskHmKgoJCP",
        "outputId": "a6666684-5439-461f-bbab-4debd55f27c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /home/gaurab/anaconda3/envs/pytorch/lib/python3.10/site-packages (4.27.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/gaurab/anaconda3/envs/pytorch/lib/python3.10/site-packages (from transformers) (1.24.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/gaurab/anaconda3/envs/pytorch/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: filelock in /home/gaurab/.local/lib/python3.10/site-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /home/gaurab/anaconda3/envs/pytorch/lib/python3.10/site-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/gaurab/anaconda3/envs/pytorch/lib/python3.10/site-packages (from transformers) (0.13.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/gaurab/anaconda3/envs/pytorch/lib/python3.10/site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/gaurab/anaconda3/envs/pytorch/lib/python3.10/site-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: requests in /home/gaurab/anaconda3/envs/pytorch/lib/python3.10/site-packages (from transformers) (2.28.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/gaurab/anaconda3/envs/pytorch/lib/python3.10/site-packages (from transformers) (2023.3.23)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/gaurab/anaconda3/envs/pytorch/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/gaurab/anaconda3/envs/pytorch/lib/python3.10/site-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/gaurab/anaconda3/envs/pytorch/lib/python3.10/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/gaurab/anaconda3/envs/pytorch/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/gaurab/anaconda3/envs/pytorch/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lww2Jo_TGiXx"
      },
      "source": [
        "# Data directories and file paths\n",
        "\n",
        "Paths to data files options are provide in the following cell. Uncomment the train/val/test partitions according to the desired labeling scheme:\n",
        "\n",
        "- filenames with 'major' are labeled with the 'major' metadata column text\n",
        "- filenames without are labeled with the 'impression' metadata column text\n",
        "- filenames with 'multi' are labeled for multiclass classification\n",
        "- filename without 'multi' are labeled for binary classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "y7d6Ny-lGef1"
      },
      "outputs": [],
      "source": [
        "#train_file = \"image_labels_impression_frontal_train.jsonl\"\n",
        "#val_file = \"image_labels_impression_frontal_val.jsonl\"\n",
        "#test_file = \"image_labels_impression_frontal_test.jsonl\"\n",
        "\n",
        "#train_file = \"image_multi_labels_major_findings_frontal_train.jsonl\"\n",
        "#val_file = \"image_multi_labels_major_findings_frontal_val.jsonl\"\n",
        "#test_file = \"image_multi_labels_major_findings_frontal_test.jsonl\"\n",
        "\n",
        "\n",
        "#train_file = \"image_labels_major_findings_frontal_train.jsonl\"\n",
        "#val_file = \"image_labels_major_findings_frontal_val.jsonl\"\n",
        "#test_file = \"image_labels_major_findings_frontal_test.jsonl\"\n",
        "\n",
        "\n",
        "train_file = \"image_labels_findings_frontal_train.jsonl\"\n",
        "val_file = \"image_labels_findings_frontal_val.jsonl\"\n",
        "test_file = \"image_labels_findings_frontal_test.jsonl\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rodBL17AuSJ6"
      },
      "source": [
        "## Import Required Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "dNP7dJV2hTKG"
      },
      "outputs": [],
      "source": [
        "from textBert_utils import set_seed\n",
        "from MMBT.image import ImageEncoderDenseNet\n",
        "from MMBT.mmbt_config import MMBTConfig\n",
        "from MMBT.mmbt import MMBTForClassification\n",
        "import tqdm as notebook_tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "sqM0DScsmCnX"
      },
      "outputs": [],
      "source": [
        "from MMBT.mmbt_utils import JsonlDataset, get_image_transforms, get_labels, load_examples, collate_fn, get_multiclass_labels, get_multiclass_criterion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0wUXVNbSoBVo"
      },
      "outputs": [],
      "source": [
        "import argparse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Th_vPKXcpn4R"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import logging\n",
        "import random\n",
        "import json\n",
        "import os\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "from matplotlib.pyplot import imshow\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "lWUF76E4y1CC"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "from transformers import (\n",
        "    WEIGHTS_NAME,\n",
        "    AdamW,\n",
        "    AutoConfig,\n",
        "    AutoModel,\n",
        "    AutoTokenizer,\n",
        "    get_linear_schedule_with_warmup,\n",
        ")\n",
        "\n",
        "try:\n",
        "    from torch.utils.tensorboard import SummaryWriter\n",
        "except ImportError:\n",
        "    from tensorboardX import SummaryWriter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWgdU7lBnyFd"
      },
      "source": [
        "# Set-up Experiment Hyperparameters and Arguments\n",
        "\n",
        "Specify the training, validation, and test files to run the experiment on. The default here is running the model on 'impression' texts.  \n",
        "\n",
        "To re-make the training, validation, and test data, please refer to the information in the **data/** directory.  \n",
        "\n",
        "Change the default values in the parser.add_argument function for the hyperparameters that you want to specify in the following cell or use the default option.  \n",
        "\n",
        "For multiple experiment runs, please make sure to change the `output_dir` argument so that new results don't overwrit existing ones.\n",
        "\n",
        "The arguments specified here are the same as in the `run_mmimdb.py` file \n",
        "in the [Huggingface example implementation of MMBT.](https://github.com/huggingface/transformers/blob/8ea412a86faa8e9edeeb6b5c46b08def06aa03ea/examples/research_projects/mm-imdb/run_mmimdb.py#L305)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "urly6ofboEmU"
      },
      "outputs": [],
      "source": [
        "parser = argparse.ArgumentParser(f'Project Hyperparameters and Other Configurations Argument Parser')\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "\n",
        "# Required parameters\n",
        "parser.add_argument(\n",
        "    \"--data_dir\",\n",
        "    default=\"data/json\",\n",
        "    type=str,\n",
        "    help=\"The input data dir. Should contain the .jsonl files.\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--model_name\",\n",
        "    default=\"bert-base-uncased\",\n",
        "    type=str,\n",
        "    help=\"model identifier from huggingface.co/models\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--output_dir\",\n",
        "    default=\"mmbt_output_findings_10epochs_n\",\n",
        "    type=str,\n",
        "    help=\"The output directory where the model predictions and checkpoints will be written.\",\n",
        ")\n",
        "\n",
        "    \n",
        "parser.add_argument(\n",
        "    \"--config_name\", default=\"bert-base-uncased\", type=str, help=\"Pretrained config name if not the same as model_name\"\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--tokenizer_name\",\n",
        "    default=\"bert-base-uncased\",\n",
        "    type=str,\n",
        "    help=\"Pretrained tokenizer name or path if not the same as model_name\",\n",
        ")\n",
        "\n",
        "parser.add_argument(\"--train_batch_size\", default=32, type=int, help=\"Batch size for training.\")\n",
        "parser.add_argument(\n",
        "    \"--eval_batch_size\", default=32, type=int, help=\"Batch size for evaluation.\"\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--max_seq_length\",\n",
        "    default=300,\n",
        "    type=int,\n",
        "    help=\"The maximum total input sequence length after tokenization. Sequences longer \"\n",
        "    \"than this will be truncated, sequences shorter will be padded.\",\n",
        ")\n",
        "parser.add_argument(\n",
        "    \"--num_image_embeds\", default=3, type=int, help=\"Number of Image Embeddings from the Image Encoder\"\n",
        ")\n",
        "parser.add_argument(\"--do_train\", default=True, type=bool, help=\"Whether to run training.\")\n",
        "parser.add_argument(\"--do_eval\", default=True, type=bool, help=\"Whether to run eval on the dev set.\")\n",
        "parser.add_argument(\n",
        "    \"--evaluate_during_training\", default=True, type=bool, help=\"Run evaluation during training at each logging step.\"\n",
        ")\n",
        "\n",
        "\n",
        "parser.add_argument(\n",
        "    \"--gradient_accumulation_steps\",\n",
        "    type=int,\n",
        "    default=1,\n",
        "    help=\"Number of updates steps to accumulate before performing a backward/update pass.\",\n",
        ")\n",
        "parser.add_argument(\"--learning_rate\", default=5e-5, type=float, help=\"The initial learning rate for Adam.\")\n",
        "parser.add_argument(\"--weight_decay\", default=0.1, type=float, help=\"Weight deay if we apply some.\")\n",
        "parser.add_argument(\"--adam_epsilon\", default=1e-8, type=float, help=\"Epsilon for Adam optimizer.\")\n",
        "parser.add_argument(\"--max_grad_norm\", default=1.0, type=float, help=\"Max gradient norm.\")\n",
        "parser.add_argument(\n",
        "    \"--num_train_epochs\", default=10.0, type=float, help=\"Total number of training epochs to perform.\"\n",
        ")\n",
        "parser.add_argument(\"--patience\", default=5, type=int, help=\"Patience for Early Stopping.\")\n",
        "parser.add_argument(\n",
        "    \"--max_steps\",\n",
        "    default=-1,\n",
        "    type=int,\n",
        "    help=\"If > 0: set total number of training steps to perform. Override num_train_epochs.\",\n",
        ")\n",
        "parser.add_argument(\"--warmup_steps\", default=0, type=int, help=\"Linear warmup over warmup_steps.\")\n",
        "\n",
        "parser.add_argument(\"--logging_steps\", type=int, default=25, help=\"Log every X updates steps.\")\n",
        "parser.add_argument(\"--save_steps\", type=int, default=25, help=\"Save checkpoint every X updates steps.\")\n",
        "parser.add_argument(\n",
        "    \"--eval_all_checkpoints\",\n",
        "    default=True, type=bool,\n",
        "    help=\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\",\n",
        ")\n",
        "\n",
        "parser.add_argument(\"--num_workers\", type=int, default=8, help=\"number of worker threads for dataloading\")\n",
        "\n",
        "parser.add_argument(\"--seed\", type=int, default=42, help=\"random seed for initialization\")\n",
        "\n",
        "\n",
        "args = parser.parse_args(\"\")\n",
        "\n",
        "# Setup CUDA, GPU & distributed training\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "args.n_gpu = torch.cuda.device_count() if torch.cuda.is_available() else 0\n",
        "args.device = device\n",
        "\n",
        "# for multiclass labeling\n",
        "args.multiclass = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "YBKm89HqqqO6"
      },
      "outputs": [],
      "source": [
        "# Setup Train/Val/Test filenames\n",
        "args.train_file = train_file\n",
        "args.val_file = val_file\n",
        "args.test_file = test_file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lKOToFXcKxs1"
      },
      "source": [
        "## Showing a sample from JsonDataset\n",
        "i.e. calling \"\\_\\_getitem\\_\\_\"\n",
        "\n",
        "Note:   \n",
        "image_end_token is the BERT token id for [SEP].   \n",
        "image_start_token is the BERT token id for [CLS]. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213,
          "referenced_widgets": [
            "8bdccab5e09f42e5b58252eab4a70fa7",
            "610859db3e0844429e6c918352666b41",
            "6cca73cef3ec46dfba68b3772e48931d",
            "80971406cec54ad8ae5388cf4f82960f",
            "7c7434fab8734b66b1417dc838dab0b0",
            "33687c7989f84e2c884f944fa2ff5706",
            "bd40889838b64e00bb92c7c473e961fa",
            "c7b29c37aaa74e8d8eb9f29da56459a2",
            "5ff5a1db9071449abf73f8a110c34e92",
            "f12d1dddf3da46a5add8135a25504769",
            "eeef0d6fb2624f0486f7f5d5e8b3c75c",
            "b5f6a624ac164172b5c02e62687bc702",
            "c1c1d8a58e054fe38dc423d161b9b383",
            "a21db7c9e0df40d7be334c0ab941331f",
            "2083b916079e4d7693904630a5cce0cb",
            "bf963dcb3e694911a30304ad2a4adc05",
            "d99f3894e8774400acac3d0456abcb5c",
            "090b18d45410423caeb15338cbe522e1",
            "2c2e3375f3e442b49679ac766512d2dd",
            "d7da24da55684219a6d38e4b9f5e357f",
            "d67751e6d9de451985b93fc386d04d11",
            "c2175698921e4b4e84a97c3b9171c625",
            "25dcdfe37c334ad6b2b85e482993bd80",
            "43ed0d606b2e496187bffe8203a90677",
            "2b7bd8e4adaf40b4bb9f8edb5bc0d110",
            "594cca03cd1a42418aefb09dbf72d6c0",
            "770d8fc7a2f44e338b07d374a80d1e5f",
            "e9afeb5388074100827646cf7447b226",
            "4f25f192789149fba7ba620174f62527",
            "7e55c33eb1a54fbf822c41caa2d768f5",
            "a74976d79c754367867f46010bc85433",
            "9aa7505b36e347a8b9287cbcd1e6988d"
          ]
        },
        "id": "h_cC7-CQFKyP",
        "outputId": "ba4db412-a59d-47f9-86a9-d20bc5fcfec8"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "        args.tokenizer_name if args.tokenizer_name else args.model_name,\n",
        "        do_lower_case=True,\n",
        "        cache_dir=None,\n",
        "    )\n",
        "train_dataset = load_examples(tokenizer, args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S80TAkjvJ9ZC",
        "outputId": "5cfddb4f-50fe-4347-9816-5dfc3e68f3e9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'image_start_token': tensor(101),\n",
              " 'image_end_token': tensor(102),\n",
              " 'sentence': tensor([ 8948,  3961, 23760, 10288,  9739,  5732,  1012,  2053,  2689,  1999,\n",
              "          1996,  2157,  2690, 21833,  6728,  6305,  9031,  1012,  2053, 22038,\n",
              "         20348, 29543,  2015,  2030, 11678,  1012, 21908, 28915,  2024,  4069,\n",
              "         25497,  1012]),\n",
              " 'image': tensor([[[-0.7650, -0.7479, -0.7308,  ..., -0.3541, -0.3369, -0.3198],\n",
              "          [-0.7137, -0.7137, -0.6794,  ..., -0.2171, -0.1828, -0.1999],\n",
              "          [-0.6109, -0.6109, -0.6109,  ..., -0.1143, -0.0801, -0.0801],\n",
              "          ...,\n",
              "          [ 1.8722,  1.9064,  1.9064,  ...,  1.6324,  1.6667,  1.7523],\n",
              "          [ 1.8893,  1.9064,  1.9407,  ...,  1.6153,  1.6838,  1.7523],\n",
              "          [ 1.8722,  1.9064,  1.9407,  ...,  1.6324,  1.7180,  1.7694]],\n",
              " \n",
              "         [[-0.6527, -0.6352, -0.6176,  ..., -0.2325, -0.2150, -0.1975],\n",
              "          [-0.6001, -0.6001, -0.5651,  ..., -0.0924, -0.0574, -0.0749],\n",
              "          [-0.4951, -0.4951, -0.4951,  ...,  0.0126,  0.0476,  0.0476],\n",
              "          ...,\n",
              "          [ 2.0434,  2.0784,  2.0784,  ...,  1.7983,  1.8333,  1.9209],\n",
              "          [ 2.0609,  2.0784,  2.1134,  ...,  1.7808,  1.8508,  1.9209],\n",
              "          [ 2.0434,  2.0784,  2.1134,  ...,  1.7983,  1.8859,  1.9384]],\n",
              " \n",
              "         [[-0.4275, -0.4101, -0.3927,  ..., -0.0092,  0.0082,  0.0256],\n",
              "          [-0.3753, -0.3753, -0.3404,  ...,  0.1302,  0.1651,  0.1476],\n",
              "          [-0.2707, -0.2707, -0.2707,  ...,  0.2348,  0.2696,  0.2696],\n",
              "          ...,\n",
              "          [ 2.2566,  2.2914,  2.2914,  ...,  2.0125,  2.0474,  2.1346],\n",
              "          [ 2.2740,  2.2914,  2.3263,  ...,  1.9951,  2.0648,  2.1346],\n",
              "          [ 2.2566,  2.2914,  2.3263,  ...,  2.0125,  2.0997,  2.1520]]]),\n",
              " 'label': tensor([1])}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_qY3Xe7Owyq"
      },
      "source": [
        "\n",
        "### Training and Evaluating Functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "z0es3QJnQY7V"
      },
      "outputs": [],
      "source": [
        "def train(args, train_dataset, model, tokenizer):\n",
        "    \"\"\" Train the model \"\"\"\n",
        "    \n",
        "    # add the spexified batch size and output dir for current run to Tensorboard \n",
        "    # saved run's name for easy identifiation\n",
        "    comment = f\"train_{args.output_dir}_{args.train_batch_size}\"\n",
        "    tb_writer = SummaryWriter(comment=comment)\n",
        "\n",
        "    train_sampler = RandomSampler(train_dataset)\n",
        "    train_dataloader = DataLoader(\n",
        "        train_dataset,\n",
        "        sampler=train_sampler,\n",
        "        batch_size=args.train_batch_size,\n",
        "        collate_fn=collate_fn\n",
        "    )\n",
        "\n",
        "    t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
        "\n",
        "    # Prepare optimizer and schedule (linear warmup and decay)\n",
        "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\n",
        "            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
        "            \"weight_decay\": args.weight_decay,\n",
        "        },\n",
        "        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
        "    ]\n",
        "\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr=args.learning_rate, eps=args.adam_epsilon)\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer, num_warmup_steps=args.warmup_steps, num_training_steps=t_total\n",
        "    )\n",
        "    \n",
        "\n",
        "    # Train!\n",
        "    logger.info(\"***** Running training *****\")\n",
        "    logger.info(\"  Num examples = %d\", len(train_dataset))\n",
        "    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n",
        "    logger.info(\n",
        "        \"  Total train batch size = %d\",\n",
        "        args.train_batch_size\n",
        "        * args.gradient_accumulation_steps)\n",
        "    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n",
        "    logger.info(\"  Total optimization steps = %d\", t_total)\n",
        "\n",
        "    global_step = 0\n",
        "    tr_loss, logging_loss = 0.0, 0.0\n",
        "    best_eval_metric, n_no_improve = 0, 0\n",
        "    model.train()\n",
        "    model.zero_grad()\n",
        "    optimizer.zero_grad()\n",
        "    train_iterator = trange(int(args.num_train_epochs), desc=\"Epoch\")\n",
        "    set_seed(args)  # Added here for reproductibility\n",
        "    for _ in train_iterator:\n",
        "        epoch_iterator = tqdm(train_dataloader, desc=\"Training Batch Iteration\")\n",
        "        for step, batch in enumerate(epoch_iterator):\n",
        "            # model.train()\n",
        "            # each sample in batch is a tuple\n",
        "            # batch is the return of the collate_fn function\n",
        "            # see function definition for data tuple order\n",
        "            batch = tuple(t.to(args.device) for t in batch)\n",
        "            labels = batch[5]\n",
        "            input_ids = batch[0]\n",
        "            input_modal = batch[2]\n",
        "            attention_mask = batch[1]\n",
        "            modal_start_tokens = batch[3]\n",
        "            modal_end_tokens = batch[4]\n",
        "\n",
        "            #inputs = {\n",
        "            #    \"input_ids\": batch[0],\n",
        "            #    \"input_modal\": batch[2],\n",
        "            #    \"attention_mask\": batch[1],\n",
        "            #    \"modal_start_tokens\": batch[3],\n",
        "            #    \"modal_end_tokens\": batch[4],\n",
        "            #    \"labels\": batch[5]\n",
        "            #}\n",
        "\n",
        "            if args.multiclass:\n",
        "                outputs = model(\n",
        "                    input_modal,\n",
        "                    input_ids=input_ids,\n",
        "                    modal_start_tokens=modal_start_tokens,\n",
        "                    modal_end_tokens=modal_end_tokens,\n",
        "                    attention_mask=attention_mask,\n",
        "                    token_type_ids=None,\n",
        "                    modal_token_type_ids=None,\n",
        "                    position_ids=None,\n",
        "                    modal_position_ids=None,\n",
        "                    head_mask=None,\n",
        "                    inputs_embeds=None,\n",
        "                    labels=None,\n",
        "                    return_dict=True\n",
        "                )\n",
        "            else:\n",
        "                outputs = model(\n",
        "                    input_modal,\n",
        "                    input_ids=input_ids,\n",
        "                    modal_start_tokens=modal_start_tokens,\n",
        "                    modal_end_tokens=modal_end_tokens,\n",
        "                    attention_mask=attention_mask,\n",
        "                    token_type_ids=None,\n",
        "                    modal_token_type_ids=None,\n",
        "                    position_ids=None,\n",
        "                    modal_position_ids=None,\n",
        "                    head_mask=None,\n",
        "                    inputs_embeds=None,\n",
        "                    labels=labels,\n",
        "                    return_dict=True\n",
        "                )\n",
        "            #logits = outputs[0]  # model outputs are always tuple in transformers (see doc)\n",
        "            logits = outputs.logits\n",
        "            if args.multiclass:\n",
        "                criterion = get_multiclass_criterion(train_dataset)\n",
        "                loss = criterion(logits, labels)\n",
        "            else:\n",
        "                loss = outputs.loss\n",
        "            \n",
        "            \n",
        "            if args.n_gpu > 1:\n",
        "                loss = loss.mean()  # mean() to average on multi-gpu parallel training\n",
        "            if args.gradient_accumulation_steps > 1:\n",
        "                loss = loss / args.gradient_accumulation_steps\n",
        "\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            tr_loss += loss.item()\n",
        "            if (step + 1) % args.gradient_accumulation_steps == 0:\n",
        "\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), args.max_grad_norm)\n",
        "\n",
        "                optimizer.step()\n",
        "                scheduler.step()  # Update learning rate schedule\n",
        "                model.zero_grad()\n",
        "                global_step += 1\n",
        "\n",
        "                if args.logging_steps > 0 and global_step % args.logging_steps == 0:\n",
        "                    logs = {}\n",
        "                    if args.evaluate_during_training:  \n",
        "                        # Only evaluate when single GPU otherwise metrics may not average well\n",
        "                        results = evaluate(args, model, tokenizer)\n",
        "                        for key, value in results.items():\n",
        "                            eval_key = \"eval_{}\".format(key)\n",
        "                            logs[eval_key] = value\n",
        "\n",
        "                    loss_scalar = (tr_loss - logging_loss) / args.logging_steps\n",
        "                    learning_rate_scalar = scheduler.get_last_lr()[0]\n",
        "                    logs[\"learning_rate\"] = learning_rate_scalar\n",
        "                    logs[\"training_loss\"] = loss_scalar\n",
        "                    logging_loss = tr_loss\n",
        "\n",
        "                    for key, value in logs.items():\n",
        "                        tb_writer.add_scalar(key, value, global_step)\n",
        "                    print(json.dumps({**logs, **{\"step\": global_step}}))\n",
        "\n",
        "                if args.save_steps > 0 and global_step % args.save_steps == 0:\n",
        "                    # Save model checkpoint\n",
        "                    output_dir = os.path.join(args.output_dir, \"checkpoint-{}\".format(global_step))\n",
        "                    if not os.path.exists(output_dir):\n",
        "                        os.makedirs(output_dir)\n",
        "                    model_to_save = (\n",
        "                        model.module if hasattr(model, \"module\") else model\n",
        "                    )  # Take care of distributed/parallel training\n",
        "                    torch.save(model_to_save.state_dict(), os.path.join(output_dir, WEIGHTS_NAME))\n",
        "                    # uncomment below to be able to save args\n",
        "                    # torch.save(args, os.path.join(output_dir, \"training_args.bin\"))\n",
        "                    logger.info(\"Saving model checkpoint to %s\", output_dir)\n",
        "\n",
        "\n",
        "        results = evaluate(args, model, tokenizer)\n",
        "        if args.multiclass:\n",
        "            eval_result = results[\"micro_f1\"]\n",
        "        else:\n",
        "            eval_result = results[\"accuracy\"]\n",
        "\n",
        "        if eval_result > best_eval_metric:\n",
        "            best_eval_metric = eval_result\n",
        "            n_no_improve = 0\n",
        "        else:\n",
        "            n_no_improve += 1\n",
        "\n",
        "        if n_no_improve > args.patience:\n",
        "            train_iterator.close()\n",
        "            break\n",
        "\n",
        "    tb_writer.close()\n",
        "\n",
        "    return global_step, tr_loss / global_step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "hwg0asA2Zm6P"
      },
      "outputs": [],
      "source": [
        "def evaluate(args, model, tokenizer, evaluate=True, test=False, prefix=\"\"):\n",
        "    \n",
        "    if test:\n",
        "        # start a separate tensorboard to track testing eval result\n",
        "        comment = f\"test_{args.output_dir}_{args.eval_batch_size}\"\n",
        "        tb_writer = SummaryWriter(comment=comment)\n",
        "\n",
        "    eval_output_dir = args.output_dir\n",
        "    eval_dataset = load_examples(tokenizer, args, evaluate=evaluate, test=test)\n",
        "\n",
        "    if not os.path.exists(eval_output_dir):\n",
        "        os.makedirs(eval_output_dir)\n",
        "\n",
        "    \n",
        "    eval_sampler = SequentialSampler(eval_dataset)\n",
        "    eval_dataloader = DataLoader(\n",
        "        eval_dataset, sampler=eval_sampler, batch_size=args.eval_batch_size, collate_fn=collate_fn\n",
        "    )\n",
        "\n",
        "    # Eval!\n",
        "    logger.info(\"***** Running evaluation {} *****\".format(prefix))\n",
        "    logger.info(\"  Num examples = %d\", len(eval_dataset))\n",
        "    logger.info(\"  Batch size = %d\", args.eval_batch_size)\n",
        "    eval_loss = 0.0\n",
        "    nb_eval_steps = 0\n",
        "    preds = []\n",
        "    out_label_ids = []\n",
        "    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
        "        model.eval()\n",
        "        batch = tuple(t.to(args.device) for t in batch)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            batch = tuple(t.to(args.device) for t in batch)\n",
        "            labels = batch[5]\n",
        "            input_ids = batch[0]\n",
        "            input_modal = batch[2]\n",
        "            attention_mask = batch[1]\n",
        "            modal_start_tokens = batch[3]\n",
        "            modal_end_tokens = batch[4]\n",
        "            \n",
        "            if args.multiclass:\n",
        "                outputs = model(\n",
        "                    input_modal,\n",
        "                    input_ids=input_ids,\n",
        "                    modal_start_tokens=modal_start_tokens,\n",
        "                    modal_end_tokens=modal_end_tokens,\n",
        "                    attention_mask=attention_mask,\n",
        "                    token_type_ids=None,\n",
        "                    modal_token_type_ids=None,\n",
        "                    position_ids=None,\n",
        "                    modal_position_ids=None,\n",
        "                    head_mask=None,\n",
        "                    inputs_embeds=None,\n",
        "                    labels=None,\n",
        "                    return_dict=True\n",
        "                )\n",
        "            else:\n",
        "                outputs = model(\n",
        "                    input_modal,\n",
        "                    input_ids=input_ids,\n",
        "                    modal_start_tokens=modal_start_tokens,\n",
        "                    modal_end_tokens=modal_end_tokens,\n",
        "                    attention_mask=attention_mask,\n",
        "                    token_type_ids=None,\n",
        "                    modal_token_type_ids=None,\n",
        "                    position_ids=None,\n",
        "                    modal_position_ids=None,\n",
        "                    head_mask=None,\n",
        "                    inputs_embeds=None,\n",
        "                    labels=labels,\n",
        "                    return_dict=True\n",
        "                )\n",
        "            #logits = outputs[0]  # model outputs are always tuple in transformers (see doc)\n",
        "            #tmp_eval_loss = criterion(logits, labels)\n",
        "            logits = outputs.logits\n",
        "            if args.multiclass:\n",
        "                criterion = get_multiclass_criterion(eval_dataset)\n",
        "                tmp_eval_loss = criterion(logits, labels)\n",
        "            else:\n",
        "                tmp_eval_loss = outputs.loss\n",
        "            eval_loss += tmp_eval_loss.mean().item()\n",
        "        nb_eval_steps += 1\n",
        "        # Move logits and labels to CPU\n",
        "        if args.multiclass:\n",
        "            pred = torch.sigmoid(logits).cpu().detach().numpy() > 0.5\n",
        "        else:            \n",
        "            pred = torch.nn.functional.softmax(logits, dim=1).argmax(dim=1).cpu().detach().numpy()\n",
        "        out_label_id = labels.detach().cpu().numpy()\n",
        "        preds.append(pred)\n",
        "        out_label_ids.append(out_label_id)\n",
        "\n",
        "    eval_loss = eval_loss / nb_eval_steps\n",
        "\n",
        "    result = {\"loss\": eval_loss}\n",
        "\n",
        "    if args.multiclass:\n",
        "        tgts = np.vstack(out_label_ids)\n",
        "        preds = np.vstack(preds)\n",
        "        result[\"macro_f1\"] = f1_score(tgts, preds, average=\"macro\")\n",
        "        result[\"micro_f1\"] = f1_score(tgts, preds, average=\"micro\")\n",
        "    else:\n",
        "        preds = [l for sl in preds for l in sl]\n",
        "        out_label_ids = [l for sl in out_label_ids for l in sl]\n",
        "        result[\"accuracy\"] = accuracy_score(out_label_ids, preds)\n",
        "\n",
        "    output_eval_file = os.path.join(eval_output_dir, prefix, \"eval_results.txt\")\n",
        "    with open(output_eval_file, \"w\") as writer:\n",
        "        logger.info(\"***** Eval results {} *****\".format(prefix))\n",
        "        for key in sorted(result.keys()):\n",
        "            logger.info(\"  %s = %s\", key, str(result[key]))\n",
        "            writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
        "            if test:\n",
        "                tb_writer.add_scalar(f'eval_{key}', result[key], nb_eval_steps)\n",
        "    \n",
        "    if test:\n",
        "        tb_writer.close()\n",
        "\n",
        "\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mrKUcxxcbs3"
      },
      "source": [
        "## Training MMBT Model \n",
        "\n",
        "Set up logging and the MMBT Model. Similar to the text-only model, check points \n",
        "are saved during a similar customizable interval.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "-3-ZxIuRcdfO"
      },
      "outputs": [],
      "source": [
        "# Setup logging\n",
        "logger = logging.getLogger(__name__)\n",
        "if not os.path.exists(args.output_dir):\n",
        "    os.makedirs(args.output_dir)\n",
        "logging.basicConfig(format=\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\",\n",
        "                    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
        "                    filename=os.path.join(args.output_dir, f\"{os.path.splitext(args.train_file)[0]}_logging.txt\"),\n",
        "                    level=logging.INFO)\n",
        "logger.warning(\"device: %s, n_gpu: %s\",\n",
        "        args.device,\n",
        "        args.n_gpu\n",
        ")\n",
        "# Set the verbosity to info of the Transformers logger (on main process only):\n",
        "\n",
        "# Set seed\n",
        "set_seed(args)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5ac8b95945b44ee3a9d3ae9a5fea2229",
            "82bddd54f6cc40a3a4a99500bbab1da9",
            "316cd4aa738a40a1b84dbb55d94dcdf0",
            "b3ae4308ff6c42199fdb117357d233c1",
            "66752937902b4b2fb9572d765921000c",
            "2f488f5c44c947cdab3349b3691f3c87",
            "36aad473352a4b529a9e723a91a60603",
            "90fe0ebace734314a37ba19b28aa99b6"
          ]
        },
        "id": "ZDgzsLlcc-Uk",
        "outputId": "289a97bb-d171-4f67-bc2d-6b0c25755d5d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mCanceled future for execute_request message before replies were done"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Setup model\n",
        "if args.multiclass:\n",
        "    labels = get_multiclass_labels()\n",
        "    num_labels = len(labels)\n",
        "else:\n",
        "    labels = get_labels()\n",
        "    num_labels = len(labels)\n",
        "transformer_config = AutoConfig.from_pretrained(args.config_name if args.config_name else args.model_name, num_labels=num_labels)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "        args.tokenizer_name if args.tokenizer_name else args.model_name,\n",
        "        do_lower_case=True,\n",
        "        cache_dir=None,\n",
        "    )\n",
        "transformer = AutoModel.from_pretrained(args.model_name, config=transformer_config, cache_dir=None)\n",
        "img_encoder = ImageEncoderDenseNet(num_image_embeds=args.num_image_embeds)\n",
        "multimodal_config = MMBTConfig(transformer, img_encoder, num_labels=num_labels, modal_hidden_size=1024)\n",
        "model = MMBTForClassification(transformer_config, multimodal_config)\n",
        "\n",
        "model.to(args.device)\n",
        "\n",
        "logger.info(f\"Training/evaluation parameters: {args}\")\n",
        "\n",
        "# Training\n",
        "if args.do_train:\n",
        "    train_dataset = load_examples(tokenizer, args)\n",
        "    # criterion = nn.CrossEntropyLoss\n",
        "    global_step, tr_loss = train(args, train_dataset, model, tokenizer)\n",
        "    logger.info(\" global_step = %s, average loss = %s\", global_step, tr_loss)\n",
        "\n",
        "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()\n",
        "    logger.info(\"Saving model checkpoint to %s\", args.output_dir)\n",
        "    # Save a trained model, configuration and tokenizer using `save_pretrained()`.\n",
        "    # They can then be reloaded using `from_pretrained()`\n",
        "    model_to_save = (model.module if hasattr(model, \"module\") else model)  # Take care of distributed/parallel training\n",
        "    torch.save(model_to_save.state_dict(), os.path.join(args.output_dir, WEIGHTS_NAME))\n",
        "    tokenizer.save_pretrained(args.output_dir)\n",
        "    transformer_config.save_pretrained(args.output_dir)\n",
        "    # Good practice: save your training arguments together with the trained model\n",
        "    torch.save(args, os.path.join(args.output_dir, \"training_args.bin\"))\n",
        "\n",
        "    # Load a trained model and vocabulary that you have fine-tuned\n",
        "    model = MMBTForClassification(transformer_config, multimodal_config)\n",
        "    model.load_state_dict(torch.load(os.path.join(args.output_dir, WEIGHTS_NAME)))\n",
        "    tokenizer = AutoTokenizer.from_pretrained(args.output_dir)\n",
        "    model.to(args.device)\n",
        "logger.info(\"***** Training Finished *****\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Se45Ve33_KAr"
      },
      "source": [
        "## Evaluating on the Test Set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vo2zxNJDYbmh",
        "outputId": "7b4b8285-380b-4feb-d938-035e78eb7165"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|██████████| 18/18 [03:47<00:00, 12.64s/it]\n",
            "Evaluating: 100%|██████████| 18/18 [00:10<00:00,  1.79it/s]\n",
            "Evaluating: 100%|██████████| 18/18 [00:10<00:00,  1.78it/s]\n",
            "Evaluating: 100%|██████████| 18/18 [00:10<00:00,  1.79it/s]\n",
            "Evaluating: 100%|██████████| 18/18 [00:10<00:00,  1.78it/s]\n",
            "Evaluating: 100%|██████████| 18/18 [00:10<00:00,  1.78it/s]\n",
            "Evaluating: 100%|██████████| 18/18 [00:10<00:00,  1.77it/s]\n",
            "Evaluating: 100%|██████████| 18/18 [00:10<00:00,  1.78it/s]\n",
            "Evaluating: 100%|██████████| 18/18 [00:10<00:00,  1.76it/s]\n",
            "Evaluating: 100%|██████████| 18/18 [00:10<00:00,  1.77it/s]\n",
            "Evaluating: 100%|██████████| 18/18 [00:10<00:00,  1.77it/s]\n",
            "Evaluating: 100%|██████████| 18/18 [00:10<00:00,  1.75it/s]\n",
            "Evaluating: 100%|██████████| 18/18 [00:10<00:00,  1.75it/s]\n",
            "Evaluating: 100%|██████████| 18/18 [00:10<00:00,  1.75it/s]\n",
            "Evaluating: 100%|██████████| 18/18 [00:10<00:00,  1.76it/s]\n",
            "Evaluating: 100%|██████████| 18/18 [00:10<00:00,  1.77it/s]\n",
            "Evaluating: 100%|██████████| 18/18 [00:10<00:00,  1.76it/s]\n",
            "Evaluating: 100%|██████████| 18/18 [00:10<00:00,  1.78it/s]\n",
            "Evaluating: 100%|██████████| 18/18 [00:10<00:00,  1.76it/s]\n"
          ]
        }
      ],
      "source": [
        "# Evaluation\n",
        "results = {}\n",
        "if args.do_eval:\n",
        "    checkpoints = [args.output_dir]\n",
        "    if args.eval_all_checkpoints:\n",
        "        checkpoints = list(os.path.dirname(c) \n",
        "        for c in sorted(glob.glob(args.output_dir + \"/**/\" + \n",
        "                                  WEIGHTS_NAME, recursive=False)))\n",
        "        # recursive=False because otherwise the parent diretory gets included\n",
        "        # which is not what we want; only subdirectories\n",
        "\n",
        "    logger.info(\"Evaluate the following checkpoints: %s\", checkpoints)\n",
        "\n",
        "    for checkpoint in checkpoints:\n",
        "        global_step = checkpoint.split(\"-\")[-1] if len(checkpoints) > 1 else \"\"\n",
        "        prefix = checkpoint.split(\"/\")[-1] if checkpoint.find(\"checkpoint\") != -1 else \"\"\n",
        "        model = MMBTForClassification(transformer_config, multimodal_config)\n",
        "        checkpoint = os.path.join(checkpoint, 'pytorch_model.bin')\n",
        "        model.load_state_dict(torch.load(checkpoint))\n",
        "        model.to(args.device)\n",
        "        result = evaluate(args, model, tokenizer, evaluate=True, test=True, prefix=prefix)\n",
        "        result = dict((k + \"_{}\".format(global_step), v) for k, v in result.items())\n",
        "        results.update(result)\n",
        "\n",
        "results.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mu5ge_8Yjg6w"
      },
      "outputs": [],
      "source": [
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMeqM4JD_bbV"
      },
      "source": [
        "## Saving Test Eval Results\n",
        "\n",
        "The code automatically saved evaluation result from each checkpoint in its respective folder. This next cell simply saves all of them in one place."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvH1zD7si_rg"
      },
      "outputs": [],
      "source": [
        "with open(os.path.join(args.output_dir, f\"{os.path.splitext(args.test_file)[0]}_eval_results.txt\"), mode='w', encoding='utf-8') as out_f:\n",
        "    print(results, file=out_f)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "run_mmbt.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "090b18d45410423caeb15338cbe522e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2083b916079e4d7693904630a5cce0cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25dcdfe37c334ad6b2b85e482993bd80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b7bd8e4adaf40b4bb9f8edb5bc0d110": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_770d8fc7a2f44e338b07d374a80d1e5f",
              "IPY_MODEL_e9afeb5388074100827646cf7447b226"
            ],
            "layout": "IPY_MODEL_594cca03cd1a42418aefb09dbf72d6c0"
          }
        },
        "2c2e3375f3e442b49679ac766512d2dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "Downloading: 100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2175698921e4b4e84a97c3b9171c625",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d67751e6d9de451985b93fc386d04d11",
            "value": 466062
          }
        },
        "2f488f5c44c947cdab3349b3691f3c87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "316cd4aa738a40a1b84dbb55d94dcdf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "Downloading: 100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f488f5c44c947cdab3349b3691f3c87",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66752937902b4b2fb9572d765921000c",
            "value": 440473133
          }
        },
        "33687c7989f84e2c884f944fa2ff5706": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36aad473352a4b529a9e723a91a60603": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "43ed0d606b2e496187bffe8203a90677": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f25f192789149fba7ba620174f62527": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "594cca03cd1a42418aefb09dbf72d6c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ac8b95945b44ee3a9d3ae9a5fea2229": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_316cd4aa738a40a1b84dbb55d94dcdf0",
              "IPY_MODEL_b3ae4308ff6c42199fdb117357d233c1"
            ],
            "layout": "IPY_MODEL_82bddd54f6cc40a3a4a99500bbab1da9"
          }
        },
        "5ff5a1db9071449abf73f8a110c34e92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eeef0d6fb2624f0486f7f5d5e8b3c75c",
              "IPY_MODEL_b5f6a624ac164172b5c02e62687bc702"
            ],
            "layout": "IPY_MODEL_f12d1dddf3da46a5add8135a25504769"
          }
        },
        "610859db3e0844429e6c918352666b41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66752937902b4b2fb9572d765921000c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "6cca73cef3ec46dfba68b3772e48931d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "Downloading: 100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33687c7989f84e2c884f944fa2ff5706",
            "max": 433,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7c7434fab8734b66b1417dc838dab0b0",
            "value": 433
          }
        },
        "770d8fc7a2f44e338b07d374a80d1e5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "Downloading: 100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e55c33eb1a54fbf822c41caa2d768f5",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f25f192789149fba7ba620174f62527",
            "value": 28
          }
        },
        "7c7434fab8734b66b1417dc838dab0b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "7e55c33eb1a54fbf822c41caa2d768f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80971406cec54ad8ae5388cf4f82960f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7b29c37aaa74e8d8eb9f29da56459a2",
            "placeholder": "​",
            "style": "IPY_MODEL_bd40889838b64e00bb92c7c473e961fa",
            "value": " 433/433 [00:00&lt;00:00, 904B/s]"
          }
        },
        "82bddd54f6cc40a3a4a99500bbab1da9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bdccab5e09f42e5b58252eab4a70fa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6cca73cef3ec46dfba68b3772e48931d",
              "IPY_MODEL_80971406cec54ad8ae5388cf4f82960f"
            ],
            "layout": "IPY_MODEL_610859db3e0844429e6c918352666b41"
          }
        },
        "90fe0ebace734314a37ba19b28aa99b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9aa7505b36e347a8b9287cbcd1e6988d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a21db7c9e0df40d7be334c0ab941331f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a74976d79c754367867f46010bc85433": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3ae4308ff6c42199fdb117357d233c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90fe0ebace734314a37ba19b28aa99b6",
            "placeholder": "​",
            "style": "IPY_MODEL_36aad473352a4b529a9e723a91a60603",
            "value": " 440M/440M [00:11&lt;00:00, 37.6MB/s]"
          }
        },
        "b5f6a624ac164172b5c02e62687bc702": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf963dcb3e694911a30304ad2a4adc05",
            "placeholder": "​",
            "style": "IPY_MODEL_2083b916079e4d7693904630a5cce0cb",
            "value": " 232k/232k [00:18&lt;00:00, 12.5kB/s]"
          }
        },
        "bd40889838b64e00bb92c7c473e961fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf963dcb3e694911a30304ad2a4adc05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1c1d8a58e054fe38dc423d161b9b383": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "c2175698921e4b4e84a97c3b9171c625": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7b29c37aaa74e8d8eb9f29da56459a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d67751e6d9de451985b93fc386d04d11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "d7da24da55684219a6d38e4b9f5e357f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43ed0d606b2e496187bffe8203a90677",
            "placeholder": "​",
            "style": "IPY_MODEL_25dcdfe37c334ad6b2b85e482993bd80",
            "value": " 466k/466k [00:01&lt;00:00, 395kB/s]"
          }
        },
        "d99f3894e8774400acac3d0456abcb5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c2e3375f3e442b49679ac766512d2dd",
              "IPY_MODEL_d7da24da55684219a6d38e4b9f5e357f"
            ],
            "layout": "IPY_MODEL_090b18d45410423caeb15338cbe522e1"
          }
        },
        "e9afeb5388074100827646cf7447b226": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9aa7505b36e347a8b9287cbcd1e6988d",
            "placeholder": "​",
            "style": "IPY_MODEL_a74976d79c754367867f46010bc85433",
            "value": " 28.0/28.0 [00:16&lt;00:00, 1.67B/s]"
          }
        },
        "eeef0d6fb2624f0486f7f5d5e8b3c75c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "Downloading: 100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a21db7c9e0df40d7be334c0ab941331f",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c1c1d8a58e054fe38dc423d161b9b383",
            "value": 231508
          }
        },
        "f12d1dddf3da46a5add8135a25504769": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
